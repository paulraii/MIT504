<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-5BB8W2X');</script>
  <!-- End Google Tag Manager -->
  <link rel="icon" type="image/png" href="/favicon.png"/>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>MIT 504: Technology Project Management</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-169007209-3"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-169007209-3');
  </script>

</head>

<body>
  
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5BB8W2X"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
  <!-- ======= Header ======= -->
  <header id="header" class="header-tops">
    <div class="container">
      <h1><a href="index.html">K Nearest Neighbor</a></h1>
      <h2 style="color:#fff">is <span class="typing" style="color:#12D640"></span></h2>
      <nav class="nav-menu d-none d-lg-block">
        <ul>
          <li class="active"><a href="#header"> <span>Home</span></a></li>
          <li><a href="#definition"><span>Introduction</span></a></li>
          <li><a href="#basicconcepts"> <span>Basic Concepts</span></a></li>
          <li><a href="#workflow"> <span>Algorith Workflow</span></a></li>
          <li><a href="#colabcode"> <span>Colab Demo</span></a></li>
          <li><a href="#references"> <span>References</span></a></li>
        </ul>
         
      </nav><!-- .nav-menu -->

      <!-- Social accounts 
      <div class="social-links">
        <a href="https://www.linkedin.com/in/ryanpaulpaz/" target="_blank" class="linkedin"><i class="bx bxl-linkedin"></i></a>
        <a href="https://www.github.com/paulraii" target="_blank" class="github"><i class="bx bxl-github"></i></a>
        <a href="mailto:ryanpaulpaz@gmail.com" target="_blank" class="google"><i class="bx bxl-google"></i></a>
      </div> -->
    </div>
  </header><!-- End Header -->


  <!-- ======= Definition Section ======= -->
  <section id="definition" class="definition">

    <!-- ======= Definition ======= -->
    <div class="about-me container">
      <div class="section-title pt-2">
        <h2>Short Video Presentation</h2>
      </div>
      
      <div class="row">
        <div class="col-lg-4">
         <center><iframe class="embed-responsive-item" src="https://paulraii.github.io/MIT504/k-Nearest%20Neighbors%20(k-NN).mp4" allowfullscreen width="700" height="450"></iframe></center>
        </div>
      </div>
        
      <div class="section-title pt-2">
        <h2>Definition</h2>
      </div>

      <div class="row">
        <div class="col-lg-4" data-aos="fade-right">
          <img src="assets/img/0_2_qzcm2gSe9l67aI.png" class="img-fluid" alt="">
        </div>
        <div class="col-lg-8 pt-4 pt-lg-0 content" data-aos="fade-left">
          <p style="text-align:justify">
            <strong>kNN, or the k-nearest neighbor algorithm, is a machine learning algorithm that uses proximity to compare one data point with a set of data it was trained on and has memorized to make predictions.</strong> This instance-based learning affords kNN the 'lazy learning' denomination and enables the algorithm to perform classification or regression problems. kNN works off the assumption that similar points can be found near one another — birds of a feather flock together.

As a classification algorithm, kNN assigns a new data point to the majority set within its neighbors. As a regression algorithm, kNN makes a prediction based on the average of the values closest to the query point.

kNN is a supervised learning algorithm in which 'k' represents the number of nearest neighbors considered in the classification or regression problem, and 'NN' stands for the nearest neighbors to the number chosen for k.
          </p>
          
        </div>
      </div>

    </div>

    <div class="interests container">

      <div class="section-title pt-2">
        <h2>History</h2>
      </div>
      <div class="row">
        <div class="col-lg-12 pt-4 pt-lg-0 content" data-aos="fade-left">
          <p style="text-align:justify">
            kNN was first developed by Evelyn Fix and Joseph Hodges in 1951 in the context of research performed for the US military1. They published a paper explaining discriminant analysis, which is a non-parametric classification method. In 1967, Thomas Cover and Peter Hart expanded on the non-parametric classification method and published their "Nearest Neighbor Pattern Classification" paper2. Almost 20 years later, the algorithm was refined by James Keller, who developed a "fuzzy KNN" that produces lower error rates3.

            Today, the kNN algorithm is the most widely used algorithm due to its adaptability to most fields — from genetics to finance and customer service.
          </p>
        </div>
      </div>

    </div>
  </section><!-- End About Section -->


<!-- basicconcepts Section Starts -->
  <section id="basicconcepts" class="services">
    <div class="container">
      <div class="section-title pt-2">
        <h2>Basic Concepts</h2>
      </div>
      <div class="row">
        <div class="col-lg-12 pt-4 pt-lg-0 content" data-aos="fade-up">
          <p style="text-align:justify"></p>
          The kNN algorithm works as a supervised learning algorithm, meaning it is fed training datasets it memorizes. It relies on this labeled input data to learn a function that produces an appropriate output when given new unlabeled data.

          This enables the algorithm to solve classification or regression problems. While kNN's computation occurs during a query and not during a training phase, it has important data storage requirements and is therefore heavily reliant on memory.
          
          For classification problems, the KNN algorithm will assign a class label based on a majority, meaning that it will use the label that is most frequently present around a given data point. In other words, the output of a classification problem is the mode of the nearest neighbors.
          </p>
        </div>
      </div>
    </div>  


      </div>
    </div>
  </div>

  </section>

  <section id="workflow" class="services">
    <div class="container">
      <div class="section-title">
        <h2>Algorithm Workflow</h2>
      </div>

      <div class="row">
          <div class="col-lg-12" data-aos="fade-up">
            
            <div class="col-md-12 mt-4 mt-md-0 icon-box" data-aos="fade-up" data-aos-delay="100">
              <h4 style="text-align:left;"><a href="https://codingcops.com/" style="color:#12d640">Euclidean Distance</a><br> </h4>
              <ul style="text-align:left;">
                This is nothing but the cartesian distance between the two points which are in the plane/hyperplane. Euclidean distance can also be visualized as the length of the straight line that joins the two points which are into consideration. This metric helps us calculate the net displacement done between the two states of an object.
              </ul>
                
              <span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML">
                      <semantics>
                        <mrow>
                          <mtext>distance</mtext>
                          <mo stretchy="false">(</mo>
                          <mi>x</mi>
                          <mo separator="true">,</mo>
                          <msub>
                            <mi>X</mi>
                            <mi>i</mi>
                          </msub>
                          <mo stretchy="false">)</mo>
                          <mo>=</mo>
                          <msqrt>
                            <mrow>
                              <msubsup>
                                <mo>∑</mo>
                                <mrow>
                                  <mi>j</mi>
                                  <mo>=</mo>
                                  <mn>1</mn>
                                </mrow>
                                <mi>d</mi>
                              </msubsup>
                              <mo stretchy="false">(</mo>
                              <msub>
                                <mi>x</mi>
                                <mi>j</mi>
                              </msub>
                              <mtext>–</mtext>
                              <msub>
                                <mi>X</mi>
                                <msub>
                                  <mi>i</mi>
                                  <mi>j</mi>
                                </msub>
                              </msub>
                              <msup>
                                <mo stretchy="false">)</mo>
                                <mn>2</mn>
                              </msup>
                            </mrow>
                          </msqrt>
                          <mo stretchy="false">]</mo>
                        </mrow>
                        <annotation encoding="application/x-tex">
                      </semantics></math>
            </div>

            <div class="col-md-12 mt-4 mt-md-0 icon-box" data-aos="fade-up" data-aos-delay="100">
              <h4 style="text-align:left;"><a href="https://imsciences.edu.pk/" style="color:#12d640">Manhattan Distance</a><br> </h4>
              <ul style="text-align:left;">
                Manhattan Distance metric is generally used when we are interested in the total distance traveled by the object instead of the displacement. This metric is calculated by summing the absolute difference between the coordinates of the points in n-dimensions.
              </ul>

              <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mrow><mo fence="true">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo fence="true">)</mo></mrow><mo>=</mo><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mrow><mo fence="true">∣</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><mo fence="true">∣</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">d\left ( x,y \right )={\sum_{i=1}^{n}\left | x_i-y_i \right |}
              </annotation></semantics></math>
            </div>

              <!-- IM | CIS Member -->
              <div class="col-md-12 mt-4 mt-md-0 icon-box" data-aos="fade-up" data-aos-delay="100">
                <h4 style="text-align:left;"><a href="https://imsciences.edu.pk/" style="color:#12d640">Minkowski Distance</a><br> </h4>
                
                <ul style="text-align:left;">
                  We can say that the Euclidean, as well as the Manhattan distance, are special cases of the Minkowski distance.
                </ul>

                  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mrow><mo fence="true">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo fence="true">)</mo></mrow><mo>=</mo><msup><mrow><mo fence="true">(</mo><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msup><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mi>p</mi></msup></mrow><mo fence="true">)</mo></mrow><mfrac><mn>1</mn><mi>p</mi></mfrac></msup></mrow><annotation encoding="application/x-tex">d\left ( x,y \right )=\left ( {\sum_{i=1}^{n}\left ( x_i-y_i \right )^p} \right )^{\frac{1}{p}}</annotation></semantics></math>
                
                <ul class="pt-3" style="text-align:left;">  
                    From the formula above we can say that when p = 2 then it is the same as the formula for the Euclidean distance and when p = 1 then we obtain the formula for the Manhattan distance.
                    The above-discussed metrics are most common while dealing with a Machine Learning problem but there are other distance metrics as well like Hamming Distance which come in handy while dealing with problems that require overlapping comparisons between two vectors whose contents can be Boolean as well as string values.
                </ul>
              </div>  

          </div>
        </div>
    </div>
  </section>

  <!-- End workflow Section -->


  <!-- Start colabcode Section -->
   <section id="colabcode" class="portfolio">
    <div class="container">
      
      <div class="section-title">
        <h2>Google Colab Exercises</h2>
      </div>
      
      <div class="row">
        <script src="https://gist.github.com/paulraii/61b2629345057183d2720113564c5466.js"></script>
      </div>

      <div class="row">
        <script src="https://gist.github.com/paulraii/6085bbf0ab68bc03733fe5a9db87340a.js"></script>
      </div>

      <div class="row">
        <script src="https://gist.github.com/paulraii/c07dd0ec76e5e434c3830da116ff989c.js"></script>
      </div>
      
    </div>
  </section> 
  <!-- End colabcode Section -->

  
  <!-- Start references Section -->

  <section id="references" class="contact">
    <div class="container">

      <div class="section-title">
        <h2>References</h2>
      </div>

      <div class="row mt-2">

        <div class="col-md-8 d-flex align-items-stretch p-2">
          <div class="info-box">
            <i class="bx bx-map"></i>
            <h3>Geeks for Geeks</h3>
           <p>https://www.geeksforgeeks.org/k-nearest-neighbours/</p> 
          </div>
        </div>

        <div class="col-md-8 d-flex align-items-stretch p-2">
          <div class="info-box container">
            <i class="bx bx-map"></i>
            <h3>Cornell Bowers CIS | Computer Science</h3>
           <p>https://www.cs.cornell.edu/courses/cs4780/2017sp/lectures/lecturenote02_kNN.html</p> 
          </div>
        </div>

        <div class="col-md-8 d-flex align-items-stretch p-2">
          <div class="info-box">
            <i class="bx bx-map"></i>
            <h3>Elastic</h3>
           <p>https://www.elastic.co/what-is/knn</p> 
          </div>
        </div>

        <div class="col-md-8 d-flex align-items-stretch p-2">
          <div class="info-box">
            <i class="bx bx-map"></i>
            <h3>Scikit-learn Documentation on k-NN</h3>
           <p>https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification</p> 
          </div>
        </div>

        <div class="col-md-8 d-flex align-items-stretch p-2">
          <div class="info-box">
            <i class="bx bx-map"></i>
            <h3>K-Nearest Neighbors Algorithm in Machine Learning</h3>
           <p>https://towardsdatascience.com/k-nearest-neighbors-knn-algorithm-in-machine-learning-6e2f9c8f9a3e</p> 
          </div>
        </div>

        <div class="col-md-8 d-flex align-items-stretch p-2">
          <div class="info-box">
            <i class="bx bx-map"></i>
            <h3>Understanding k-NN</h3>
           <p>https://www.analyticsvidhya.com/blog/2021/06/understanding-k-nearest-neighbors-knn-algorithm</p> 
          </div>
        </div>

        <div class="col-md-8 d-flex align-items-stretch p-2">
          <div class="info-box">
            <i class="bx bx-map"></i>
            <h3>K-Nearest Neighbors (KNN) Explained</h3>
           <p>https://www.datacamp.com/community/tutorials/k-nearest-neighbors-classification-scikit-learn</p> 
          </div>
        </div>


      </div>
    </div>
  </section>
  <!-- End references Section -->

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script src="assets/vendor/counterup/counterup.min.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script type="text/javascript">
    var typed = new Typed('.typing',{
      strings: ["a machine learning algorithm", "a supervised learning algorithm", "also known as kNN"],
      loop: true,
      typeSpeed: 65,
      backSpeed: 65
    });
  </script>

  <!-- Main JS File for the Website-->
  <script src="assets/js/main.js"></script>

</body>

</html>
